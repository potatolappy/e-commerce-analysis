# e-commerce-analysis

note: i havent even review the dataset yet, this is just a doodle brainfart

Lorem ipsum dolor imet

**Tools**

Tools used: 
- Jupyter Notebook, better suited for narrative story telling
- SQLite (DB Browser), somehow the dataset provided is in .db not .sql, so will be using this one

**Some key highlights of the project**

- Using z-scores parameter to detect outliers, and normalize the data
- cleaning / dropping null values
- formatting datatypes in SQL
- some visualizations using seaborne

**Objective:**

Theme: Location efficiency, identifying tier 1, 2 and 3 cities

1. Best selling product category
2. Revenue generated in each city
3. average logistic cost in each city

**Cleaning process**

1. inspecting shape and general info (done in Python)
2. inspecting null values (done in Python)
3. inspecting inconsistent datatype (done in SQL)
4. inspecting duplicates (done in Python)
5. inspecting outlier (done in python)

the analysis can be viewed at ```olist_analysis.ipynb```
